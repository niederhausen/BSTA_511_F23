---
title: "DRAFT: Day 12: Inference for a single proportion or difference of two (independent) proportions (Sections 8.1-8.2)"
subtitle: "BSTA 511/611"
author: "Meike Niederhausen, PhD"
institute: "OHSU-PSU School of Public Health"
date: "11/8/2023"
categories: ["Week 7"]
format: 
  revealjs:
      incremental: false
      scrollable: true
      chalkboard: true
      theme: [../sky_modified.scss]
      width:  1100 #1200 # 1050 #default 1050; ipad 3:4, 1600
      height: 825 #900 #800 #default 700; 788 for 3:4, 1200
      slide-number: true
      html-math-method: mathjax
  # html:
  #   link-external-newwindow: true
  #   toc: true
execute:
  echo: true
  freeze: auto  # re-render only when source changes
# editor: visual
editor_options: 
  chunk_output_type: console
---

```{r}
#| label: "setup" 
#| include: false
#| message: false
#| warning: false

library(tidyverse)    
library(oibiostat)
library(janitor)
library(rstatix)
library(knitr)
library(gtsummary)
library(moderndive)
library(gt)
library(broom) 
library(here) 
library(pwr) # NEW!!

# terminal: for icons
# quarto install extension quarto-ext/fontawesome

# set ggplot theme for slides 
theme_set(theme_bw(base_size = 22))
# theme_update(text = element_text(size=16))  # set global text size for ggplots

```



## Where are we?

$$point~estimate \pm z^*(or~t^*)\cdot SE,~~~~~~~~test~stat = \frac{point~estimate-null~value}{SE}$$

Day | Book | Population <br> parameter | Symbol | Point estimate | Symbol | SE 
--|--|--|--|--|--|--
11-12 | 5.1 | Pop mean | $p$ | Sample mean | $\bar{x}$ | $\frac{s}{\sqrt{n}}$ 
13 | 5.2 | Diff in paired <br> pop means | $p_d$ or $\delta$ | Diff in paired <br> sample means | $\bar{x}_{d}$  | $\frac{s_d}{\sqrt{n}}$ 
14 | 5.3 | Diff in pop <br> means | $p_1-p_2$ | Diff in sample <br> means | $\bar{x}_1 - \bar{x}_2$  | $\sqrt{\frac{s_1^2}{n_1} + \frac{s_2^2}{n_2}}$ or pooled
<span style="color:darkorange">15</span> | <span style="color:darkorange">8.1</span> | <span style="color:darkorange">Pop proportion</span> | $p$ | <span style="color:darkorange">Sample prop</span> | $\hat{p}$  | 
<span style="color:darkorange">15</span> | <span style="color:darkorange">8.2</span> | <span style="color:darkorange">Diff in pop <br> proportions</span> | $p_1-p_2$ | <span style="color:darkorange">Diff in sample <br> proportions</span> | $\hat{p}_1-\hat{p}_2$ | 






## Goals for today (Sections 8.1-8.2)

* Statistical inference for a single proportion or the difference of two (independent) proportions
    1. Sampling distribution for a proportion or difference in proportions
    
    1. What are $H_0$ and $H_a$?
    
    1. What are the SE's for $\hat{p}$ and $\hat{p}_1-\hat{p}_2$?
    
    1. Hypothesis test
    
    1. Confidence Interval
    
    1. How are the SE's different for a hypothesis test & CI?
    
    1. Run test in R



## Motivating example

__One proportion__

* A 2010 study found that out of 269 male college students, 35% had participated in sports betting in the previous year. 
    * What is the CI for the proportion?
    * The study also reported that 36% of noncollege young males had participated in sports betting. Is the proportion for male college students different from 0.36?

__Two proportions__

* There were 214 men in the sample of noncollege young males (36% participated in sports betting in the previous year).
* Compare the difference in proportions between the college and noncollege young males.
    * CI
    * Hypothesis test


Barnes GM, Welte JW, Hoffman JH, Tidwell MC. [Comparisons of gambling and alcohol use among college students and noncollege young people in the United States](https://www.tandfonline.com/doi/full/10.1080/07448480903540499?journalCode=vach20). J Am Coll Health. 2010 Mar-Apr;58(5):443-52. doi: 10.1080/07448480903540499. PMID: 20304756; PMCID: PMC4104810.



## Steps in a Hypothesis Test

1. Set the __[level of significance]{style="color:darkorange"}__ $\alpha$

1. Specify the __[null]{style="color:darkorange"}__ ( $H_0$ ) and __[alternative]{style="color:darkorange"}__ ( $H_A$ ) __[hypotheses]{style="color:darkorange"}__
    1. In symbols
    1. In words
    1. Alternative: one- or two-sided?

1. Calculate the __[test statistic]{style="color:darkorange"}__. 

1. Calculate the __[p-value]{style="color:darkorange"}__ based on the observed test statistic and its sampling distribution

1. Write a __[conclusion]{style="color:darkorange"}__ to the hypothesis test
    1. Do we reject or fail to reject $H_0$?
    1. Write a conclusion in the context of the problem


## Step 2: Null & Alternative Hypotheses 

Null and alternative hypotheses in __words__ and in __symbols__.

::: columns
::: {.column width="50%"}
__One sample test__

* $H_0$: The population proportion of young male college students that participated in sports betting in the previous year is 0.36.

* $H_A$: The population proportion of young male college students that participated in sports betting in the previous year is not 0.36.

$$~~~~H_0: p = 0.36\\
H_A: p \neq 0.36$$
:::

::: {.column width="50%"}
__Two samples test__

* $H_0$: The difference in population proportions of young male college and noncollege students that participated in sports betting in the previous year is 0.

* $H_A$: The difference in population proportions of young male college and noncollege students that participated in sports betting in the previous year is not 0.

$$~~~~H_0: p_{coll} - p_{noncoll} = 0\\
H_A: p_{coll} - p_{noncoll} \neq 0$$

:::



## Sampling distribution of $\hat{p}$ 

* $\hat{p}=\frac{X}{n}$ where $X$ is the number of "successes" and $n$ is the sample size.
* Thus, $X \sim Bin(n,p)$, where $p$ is the population proportion.
* For $n$ "big enough", the normal distribution can be used to approximate a binomial distribution:

$$Bin(n,p) \rightarrow N\Big(\mu = np, \sigma = \sqrt{np(1-p)} \Big)$$
* Since $\hat{p}=\frac{X}{n}$ is a linear transformation of $X$, we have for large n: 

$$\hat{p} \sim N\Big(\mu_{\hat{p}} = p, \sigma_{\hat{p}} = \sqrt{\frac{p(1-p)}{n}} \Big)$$

* How we apply this result to CI's and test statistics is different!!!




## Step 3: Test statistic 

::: columns
::: {.column width="50%"}
Sampling distribution of $\hat{p}$
$$\hat{p} \sim N\Big(\mu_{\hat{p}} = p, \sigma_{\hat{p}} = \sqrt{\frac{p(1-p)}{n}} \Big)$$
If we assume $H_0: p=p_0$ is true, then  

$$\hat{p} \sim N\Big(
\mu_{\hat{p}}=p_0, \sigma_{\hat{p}}=\sqrt{\frac{p_0\cdot(1-p_0)}{n}}
\Big)$$
:::

::: {.column width="50%"}


General test statistic:

$$
\text{test statistic} = \frac{point~estimate - null~value}{SE}
$$

For a one sample proportion test:

$$
\text{test statistic} = z_{\hat{p}} = \frac{\hat{p} - p_0}{\sqrt{\frac{p_0\cdot(1-p_0)}{n}}}
$$
:::
:::

<hr>

::: columns
::: {.column width="50%"}
__Example:__ A 2010 study found that out of 269 male college students, 35% had participated in sports betting in the previous year.   
What is the test statistic when testing $H_0: p=0.36$ vs. 
$H_A: p \neq 0.36$? 
:::

::: {.column width="50%"}

```{r}
#| include: false
p0 <- 0.36
n <- 269
n*.35
(ph <- 94/n)

(SEp <- sqrt(p0*(1-p0)/n))
(zp <- (ph-p0)/SEp)
```

$$z_{\hat{p}} = \frac{94/269 - 0.36}{\sqrt{\frac{0.36\cdot(1-0.36)}{269}}}$$

:::
:::




## Step "3b": Conditions satisfied?

::: columns
::: {.column width="50%"}
__Conditions__:

1. _Independent observations_ 
    * The observations were collected independently.

1. The number of __expected successes and expected failures is at least 10__.
    * $n_1 p_0 \ge 10, \ \ n_1(1-p_0)\ge 10$

:::

::: {.column width="50%"}

__Example:__ A 2010 study found that out of 269 male college students, 35% had participated in sports betting in the previous year.   
Testing $H_0: p=0.36$ vs. $H_A: p \neq 0.36$.  
Are the conditions satisfied?


```{r}
#| include: false
p0 <- 0.36
ph <- 0.35
n <- 269

n*p0
n*(1-p0)
```
:::
:::


## Step 4: p-value

The __[p-value]{style="color:darkorange"}__ is the __probability__ of obtaining a test statistic _just as extreme or more extreme_ than the observed test statistic assuming the null hypothesis $H_0$ is true. 

::: columns
::: {.column width="50%"}
```{r}
#| fig.width: 10
#| fig.height: 3.5
#| echo: false
# specify upper and lower bounds of shaded region below
mu <- 0.36
std <- 0.03

# The following figure is only an approximation of the 
# sampling distribution since I used a normal instead
# of t-distribution to make it.

ggplot(data.frame(x = c(mu-5*std, mu+5*std)), aes(x = x)) + 
  stat_function(fun = dnorm, 
                args = list(mean = mu, sd = std)) + 
  scale_y_continuous(breaks = NULL) +
  scale_x_continuous(breaks=c(mu, mu - 0.03*(1:5), mu + 0.03*(1:5))) +
  theme(axis.text.x=element_text(angle = -30, hjust = 0)) +
  labs(y = "", 
       x = "p-hat distribution") +
  geom_vline(xintercept = c(0.35, 0.37), 
             color = "red")
```

```{r}
#| fig.height: 3.5
#| fig.width: 10
#| echo: false
ggplot(data = data.frame(x = c(-5, 5)), aes(x)) + 
  stat_function(fun = dnorm, 
                args = list(mean = 0, sd = 1)) + 
  ylab("") + 
  xlab("z-dist") +
  scale_y_continuous(breaks = NULL) + 
  scale_x_continuous(breaks=c(mu, mu - (1:5), mu + (1:5))) +
  geom_vline(xintercept = c(-0.34, 0.34), 
             color = "red")
```


:::

::: {.column width="50%"}

Calculate the _p_-value:

```{r}
#| include: false
# p0 <- 0.36
# ph <- 0.35
# n <- 269
# 
# (SEp <- sqrt(p0*(1-p0)/n))
# (zp <- (ph-p0)/SEp)

pnorm(zp)
2*pnorm(zp)
```

$$2 \cdot P(\hat{p}<0.35) \\
= 2 \cdot P\Big(Z_{\hat{p}} < \frac{94/269 - 0.36}{\sqrt{\frac{0.36\cdot(1-0.36)}{269}}}\Big)\\
=2 \cdot P(Z_{\hat{p}} < -0.3607455)$$
```{r}
2*pnorm(-0.3607455)
```

:::
:::




## Step 5: Conclusion to hypothesis test

$$~~~~H_0: p = 0.36\\
H_A: p \neq 0.36$$

* Recall the $p$-value = 0.7182897
* Use $\alpha$ = 0.05.
* Do we reject or fail to reject $H_0$?

__Conclusion statement__:

* Stats class conclusion
    * There is insufficient evidence that the (population) proportion of young male college students that participated in sports betting in the previous year is different than 0.36 ( $p$-value = 0.72).

* More realistic manuscript conclusion: 
    * In a sample of 269 male college students, 35% had participated in sports betting in the previous year, which is not different from 36% ( $p$-value = 0.72).





## 95% CI for population proportion

::: columns
::: {.column width="50%"}
What to use for SE in CI formula?

$$\hat{p} \pm z^* \cdot SE_{\hat{p}}$$
:::

::: {.column width="50%"}
Sampling distribution of $\hat{p}$
$$\hat{p} \sim N\Big(\mu_{\hat{p}} = p, \sigma_{\hat{p}} = \sqrt{\frac{p(1-p)}{n}} \Big)$$

:::
:::

<hr>

::: columns
::: {.column width="50%"}
__Example:__ A 2010 study found that out of 269 male college students, 35% had participated in sports betting in the previous year.   
Find the 95% CI for the population proportion. 

:::

::: {.column width="50%"}

```{r}
#| include: false
p0 <- 0.36
ph <- 0.35
n <- 269

(SEph <- sqrt(ph*(1-ph)/n))

alpha <- 0.05
(p_area <- 1-alpha/2)

(zstar <- qnorm(p_area)) 

(moe <- zstar * SEph) 
(LB <- ph - moe)
(UB <- ph + moe)
```

$$94/269 \pm 1.96 \cdot SE_{\hat{p}}\\
SE_{\hat{p}} = \sqrt{\frac{(94/269)(1-94/269)}{269}}$$

:::
:::



__Interpretation__:  
We are 95% confident that the (population) proportion of young male college students that participated in sports betting in the previous year is in (0.29, 0.41).



## Conditions for one proportion: test vs. CI

::: columns
::: {.column width="50%"}
__Hypothesis test conditions__

1. _Independent observations_ 
    * The observations were collected independently.

1. The number of __expected__ successes and __expected__ failures is at least 10.

$$n_1 p_0 \ge 10, \ \ n_1(1-p_0)\ge 10$$
:::

::: {.column width="50%"}

__Confidence interval conditions__

1. _Independent observations_ 
    * The observations were collected independently.

1. The number of successes and failures is at least 10:

$$n_1\hat{p}_1 \ge 10, \ \ n_1(1-\hat{p}_1)\ge 10$$

:::
:::

```{r}
#| include: false
p0 <- 0.36
ph <- 0.35
n <- 269

n*p0
n*(1-p0)

n*ph
n*(1-ph)
```





## Sampling distribution of $\hat{p}_1-\hat{p}_2$ 

* $\hat{p}_1=\frac{X_1}{n_1}$ and $\hat{p}_2=\frac{X_2}{n_2}$, where $X_1$ & $X_2$ are the number of "successes" and $n_1$ & $n_2$ are the sample sizes of the 1st & 2nd samples, with population proportions $p_1$ & $p_2$, respectively.
* On the previous slide we saw that $\hat{p}$ can be approximated by a normal distribution.
* Since the difference of independent normal random variables is also independent, it follows that for $n_1$ and $n_2$ "big enough"

$$\hat{p}_1 - \hat{p}_2 \sim N \Big(\mu_{\hat{p}_1 - \hat{p}_2} = p_1 - p_2, ~~
\sigma_{\hat{p}_1 - \hat{p}_2} =
\sqrt{
\frac{p_1\cdot(1-p_1)}{n_1} + \frac{p_2\cdot(1-p_2)}{n_2}} 
\Big)$$

* How we apply this result to CI's and test statistics is different!!!



## Step 3: Test statistic (1/2)

Sampling distribution of $\hat{p}_1 - \hat{p}_2$:
$$\hat{p}_1 - \hat{p}_2 \sim N \Big(\mu_{\hat{p}_1 - \hat{p}_2} = p_1 - p_2, ~~
\sigma_{\hat{p}_1 - \hat{p}_2} =
\sqrt{
\frac{p_1\cdot(1-p_1)}{n_1} + \frac{p_2\cdot(1-p_2)}{n_2}} 
\Big)$$

If we assume $H_0: p_1=p_2$ is true, then we "pool" the proportions of the two samples to calculate the SE:

$$pooled~proportion = \hat{p} = \dfrac{\text{total number of successes} }{ \text{total number of cases}} = \frac{x_1+x_2}{n_1+n_2}$$ 


Test statistic:

$$
\text{test statistic} = z_{\hat{p}_1 - \hat{p}_2} = \frac{\hat{p}_1 - \hat{p}_2 - 0}{\sqrt{\frac{\hat{p}\cdot(1-\hat{p})}{n_1} + \frac{\hat{p}\cdot(1-\hat{p})}{n_2}}}
$$





## Step 3: Test statistic (2/2)


$$
\text{test statistic} = z_{\hat{p}_1 - \hat{p}_2} = \frac{\hat{p}_1 - \hat{p}_2 - 0}{\sqrt{\frac{\hat{p}\cdot(1-\hat{p})}{n_1} + \frac{\hat{p}\cdot(1-\hat{p})}{n_2}}}
$$
$$pooled~proportion = \hat{p} = \dfrac{\text{total number of successes} }{ \text{total number of cases}} = \frac{x_1+x_2}{n_1+n_2}$$ 
<hr>

::: columns
::: {.column width="50%"}

__Example:__ A 2010 study found that out of 269 male college students, 35% had participated in sports betting in the previous year, and out of 214 noncollege young males 36% had.  
What is the test statistic when testing $H_0: p_{coll} - p_{noncoll} = 0$ vs. 
$H_A: p_{coll} - p_{noncoll} \neq 0$? 
:::

::: {.column width="50%"}

```{r}
#| include: false
n1 <- 269
n2 <- 214
0.35*n1
0.36*n2
(x1 <- 94)
(x2 <- 77)
(p1 <- x1/n1)
(p2 <- x2/n2)
(ppool <- (x1+x2)/(n1+n2))

(SEpool <- sqrt(ppool*(1-ppool)*(1/n1+1/n2)))
(zpool <- (p1-p2)/SEpool)
```

$$z_{\hat{p}_1 - \hat{p}_2} = \frac{94/269 - 77/214-0}{\sqrt{0.354\cdot(1-0.354)(\frac{1}{269}+\frac{1}{214})}}\\
=-0.2367497$$

:::
:::




## Step "3b": Conditions satisfied?

::: columns
::: {.column width="50%"}
__Conditions__:

* _Independent observations & samples_
    * The observations were collected independently. 
    * In particular, observations from the two groups weren't paired in any meaningful way.

* The number of expected successes and expected failures is at least 10 _for each group_ - using the pooled proportion:
    * $n_1\hat{p} \ge 10, \ \ n_1(1-\hat{p}) \ge 10$
    * $n_2\hat{p} \ge 10, \ \ n_2(1-\hat{p}) \ge 10$

:::

::: {.column width="50%"}

__Example:__ A 2010 study found that out of 269 male college students, 35% had participated in sports betting in the previous year, and out of 214 noncollege young males 36% had.   
Testing $H_0: p_{coll} - p_{noncoll} = 0$ vs. 
$H_A: p_{coll} - p_{noncoll} \neq 0$? .  
Are the conditions satisfied?


```{r}
#| include: false
# p1 <- 0.35
# p2 <- 0.36
# n1 <- 269
# n2 <- 214
# (x1 <- p1*n1)
# (x2 <- p2*n2)
# (ppool <- (x1+x2)/(n1+n2))
# n1 <- 269
# 
# (SEpool <- sqrt(ppool*(1-ppool)*(1/(n1+n2))))
# (zpool <- (p1-p2)/SEpool)

n1*ppool
n1*(1-ppool)
n2*ppool
n2*(1-ppool)
```

:::
:::


## Step 4: p-value

The __[p-value]{style="color:darkorange"}__ is the __probability__ of obtaining a test statistic _just as extreme or more extreme_ than the observed test statistic assuming the null hypothesis $H_0$ is true. 

::: columns
::: {.column width="50%"}
```{r}
#| fig.width: 10
#| fig.height: 3.5
#| echo: false
# specify upper and lower bounds of shaded region below
mu <- 0
std <- 0.02

# The following figure is only an approximation of the 
# sampling distribution since I used a normal instead
# of t-distribution to make it.

ggplot(data.frame(x = c(mu-5*std, mu+5*std)), aes(x = x)) + 
  stat_function(fun = dnorm, 
                args = list(mean = mu, sd = std)) + 
  scale_y_continuous(breaks = NULL) +
  scale_x_continuous(breaks=c(mu, mu - 0.02*(1:5), mu + 0.02*(1:5))) +
  theme(axis.text.x=element_text(angle = -30, hjust = 0)) +
  labs(y = "", 
       x = "p-hat distribution") +
  geom_vline(xintercept = c(-.01, 0.01), 
             color = "red")
```

```{r}
#| fig.height: 3.5
#| fig.width: 10
#| echo: false
ggplot(data = data.frame(x = c(-5, 5)), aes(x)) + 
  stat_function(fun = dnorm, 
                args = list(mean = 0, sd = 1)) + 
  ylab("") + 
  xlab("z-dist") +
  scale_y_continuous(breaks = NULL) + 
  scale_x_continuous(breaks=c(mu, mu - (1:5), mu + (1:5))) +
  geom_vline(xintercept = c(-0.45, 0.45), 
             color = "red")
```


:::

::: {.column width="50%"}

Calculate the _p_-value:

```{r}
#| include: false
# p1 <- 0.35
# p2 <- 0.36
# n1 <- 269
# n2 <- 214
# (x1 <- p1*n1)
# (x2 <- p2*n2)
# (ppool <- (x1+x2)/(n1+n2))
# n1 <- 269
# 
# (SEpool <- sqrt(ppool*(1-ppool)*(1/(n1+n2))))
# (zpool <- (p1-p2)/SEpool)

pnorm(zpool)
2*pnorm(zpool)
```

$$2 \cdot P(\hat{p}_1 - \hat{p}_2<0.35-0.36) \\
= 2 \cdot P\Big(Z_{\hat{p}_1 - \hat{p}_2} < \\
\frac{94/269 - 77/214-0}{\sqrt{0.354\cdot(1-0.354)(\frac{1}{269}+\frac{1}{214})}}\Big)\\
=2 \cdot P(Z_{\hat{p}} < -0.2367497)$$
```{r}
2*pnorm(-0.2367497)
```

:::
:::


## Step 5: Conclusion to hypothesis test

$$~~~~H_0: p_{coll} - p_{noncoll} = 0\\
H_A: p_{coll} - p_{noncoll} \neq 0$$

* Recall the $p$-value = 0.812851
* Use $\alpha$ = 0.05.
* Do we reject or fail to reject $H_0$?

__Conclusion statement__:

* Stats class conclusion
    * There is insufficient evidence that the difference in (population) proportions of young male college and noncollege students that participated in sports betting in the previous year are different ( $p$-value = 0.81).

* More realistic manuscript conclusion: 
    * 35% of young male college students (n=269) and 36% of noncollege young males (n=214) participated in sports betting in the previous year ( $p$-value = 0.81).





## 95% CI for population difference in proportions

::: columns
::: {.column width="50%"}
What to use for SE in CI formula?

$$\hat{p}_1 - \hat{p}_2 \pm z^* \cdot SE_{\hat{p}_1 - \hat{p}_2}$$
:::

::: {.column width="50%"}
SE in sampling distribution of $\hat{p}_1 - \hat{p}_2$
$$\sigma_{\hat{p}_1 - \hat{p}_2} =
\sqrt{
\frac{p_1\cdot(1-p_1)}{n_1} + \frac{p_2\cdot(1-p_2)}{n_2}} $$

:::
:::

<hr>

::: columns
::: {.column width="50%"}
__Example:__ A 2010 study found that out of 269 male college students, 35% had participated in sports betting in the previous year, and out of 214 noncollege young males 36% had.
Find the 95% CI for the difference in population proportions. 

:::

::: {.column width="50%"}

```{r}
#| include: false
# p1 <- 0.35
# p2 <- 0.36
# n1 <- 269
# n2 <- 214
# (x1 <- p1*n1)
# (x2 <- p2*n2)
# n1 <- 269
# 
(SEp1p2 <- sqrt(p1*(1-p1)/n1 + p1*(2-p2)/n2))

alpha <- 0.05
(p_area <- 1-alpha/2)

(zstar <- qnorm(p_area)) 

(moe <- zstar * SEp1p2) 
(LB <- p1-p2 - moe)
(UB <- p1-p2 + moe)
```

$$\frac{94}{269} - \frac{77}{214} \pm 1.96 \cdot SE_{\hat{p}_1 - \hat{p}_2}$$


$$SE_{\hat{p}_1 - \hat{p}_2}=\\
\sqrt{
\frac{94/269 \cdot (1-94/269)}{269} + 
\frac{77/214 \cdot (1-77/214)}{214}}$$

:::
:::


__Interpretation__:  
We are 95% confident that the difference in (population) proportions of young male college and noncollege students that participated in sports betting in the previous year is in (-0.127, 0.106).




## Conditions for difference in proportions: test vs. CI

::: columns
::: {.column width="50%"}
__Hypothesis test conditions__

1. _Independent observations & samples_
    * The observations were collected independently. 
    * In particular, observations from the two groups weren't paired in any meaningful way.

1. The number of expected successes and expected failures is at least 10 _for each group_ - using the pooled proportion:
    * $n_1\hat{p} \ge 10, \ \ n_1(1-\hat{p}) \ge 10$
    * $n_2\hat{p} \ge 10, \ \ n_2(1-\hat{p}) \ge 10$
:::

::: {.column width="50%"}

__Confidence interval conditions__

1. _Independent observations & samples_
    * The observations were collected independently. 
    * In particular, observations from the two groups weren't paired in any meaningful way.

1. The number of expected successes and expected failures is at least 10 _for each group_.
    * $n_1\hat{p}_1 \ge 10, \ \ n_1(1-\hat{p}_1) \ge 10$
    * $n_2\hat{p}_2 \ge 10, \ \ n_2(1-\hat{p}_2) \ge 10$

:::
:::

```{r}
#| include: false
p0 <- 0.36
ph <- 0.35
n <- 269

n*p0
n*(1-p0)

n*ph
n*(1-ph)
```





## R: 1-sample proportion test (1/3)

::: columns
::: {.column width="50%"}
We first need a dataset based on the results:
```{r}
.35*269 # number of "successes"
# round this value

SportsBet1 <- tibble(
  Coll = c(rep("Bet", 94), 
              rep("NotBet",269-94))
  )
glimpse(SportsBet1)
```
:::

::: {.column width="50%"}
```{r}
SportsBet1 %>% tabyl(Coll)
```

R code for proportions test requires input as a base R `table`:
```{r}
table(SportsBet1$Coll)
```

:::
:::


## R: 1-sample proportion test (2/3)

`prop.test` requires the input x to be a table

```{r}
prop.test(x = table(SportsBet1$Coll),
       alternative = "two.sided",
       p = 0.36,
       correct = FALSE)
```




## R: 1-sample proportion test: with vs. without CC (3/3)

Apply a continuity correction (CC) to the p-value calculation.

```{r}
prop.test(x = table(SportsBet1$Coll), alternative = "two.sided",
       p = 0.36, correct = FALSE) %>% tidy() %>% gt()

prop.test(x = table(SportsBet1$Coll), alternative = "two.sided",
       p = 0.36, correct = TRUE) %>% tidy() %>% gt()
```

Differences are small when sample sizes are large.




## R: 2-samples proportions test (1/3)

::: columns
::: {.column width="50%"}
We first need a dataset based on the results:

```{r}
.35*269 # number of "successes"
.36*214 # round these value

SportsBet2 <- tibble(
  Group = c(rep("College", 269), 
         rep("NonCollege", 214)),
  Bet = c(rep("yes", 94), 
          rep("no", 269-94),
          rep("yes", 77), 
          rep("no", 214-77))
)
glimpse(SportsBet2)
```
:::

::: {.column width="50%"}
```{r}
SportsBet2 %>% tabyl(Group, Bet)
```

R code for proportions test requires input as a base R `table`:
```{r}
table(SportsBet2$Group, SportsBet2$Bet)
```

:::
:::




## R: 2-samples proportions test (2/3)

`prop.test` requires the input x to be a table

```{r}
prop.test(x = table(SportsBet2$Group, SportsBet2$Bet),
       alternative = "two.sided",
       correct = FALSE)
```




## R: 2-samples proportions test: with vs. without CC (3/3)

Apply a continuity correction (CC) to the p-value calculation.

```{r}
prop.test(x = table(SportsBet2$Group, SportsBet2$Bet), alternative = "two.sided", 
          correct = FALSE) %>% tidy() %>% gt()

prop.test(x = table(SportsBet2$Group, SportsBet2$Bet), alternative = "two.sided", 
          correct = TRUE) %>% tidy() %>% gt()
```

Differences are small when sample sizes are large.


# Power & sample size for testing proportions

