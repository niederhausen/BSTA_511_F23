{
  "hash": "50619b23f26b0198a34fa4473352633a",
  "result": {
    "markdown": "---\ntitle: \"DRAFT: Day 14: Comparing Means with ANOVA (Section 5.5)\"\nsubtitle: \"BSTA 511/611\"\nauthor: \"Meike Niederhausen, PhD\"\ninstitute: \"OHSU-PSU School of Public Health\"\ndate: \"11/20/2023\"\ncategories: [\"Week 9\"]\nformat: \n  html:\n    link-external-newwindow: true\n    toc: true\n    code-fold: show\n    code-tools: true\n    source: repo\n    html-math-method: mathjax\nexecute:\n  echo: true\n  freeze: auto  # re-render only when source changes\n# editor: visual\neditor_options: \n  chunk_output_type: console\n---\n\n\n\n\n## Load packages\n\n* Packages need to be loaded _every time_ you restart R or render an Qmd file\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# run these every time you open Rstudio\nlibrary(tidyverse)    \nlibrary(oibiostat)\nlibrary(janitor)\nlibrary(rstatix)\nlibrary(knitr)\nlibrary(gtsummary)\nlibrary(moderndive)\nlibrary(gt)\nlibrary(broom) \nlibrary(here) \nlibrary(pwr) # new-ish\n```\n:::\n\n\n\n- You can check whether a package has been loaded or not \n  - by looking at the Packages tab and \n  - seeing whether it has been checked off or not\n\n\n# Topics\n\n* When to use an ANOVA\n* Different sources of variation in ANOVA\n* ANOVA assumptions\n* Post-hoc testing of differences in means\n* Running an ANOVA in R\n\n## Additional Resource\n\n* BSTA 511 textbook (Vu & Harrington)\n    * Section 5.5: Comparing means with ANOVA\n    * Section 7.9: Connection between ANOVA and regression\n\n\n\n# Disability Discrimination Example \n\n\n* The U.S. Rehabilitation Act of 1973 prohibited discrimination against people with physical disabilities. \n    * The act defined a disabled person as any individual who has a physical or mental impairment that limits the person's major life activities.\n* A 1980's study examined whether physical disabilities affect people's perceptions of employment qualifications \n    * ([Cesare, Tannenbaum, & Dalessio, 1990](https://psycnet.apa.org/record/1991-07629-001)). \n]\n\n\n* Researchers prepared recorded job interviews, using _same actors and script each time_. \n* Only difference: job applicant appeared with different disabilities.\n    * _No disability_\n    * _Leg amputation_\n    * _Crutches_\n    * _Hearing impairment_\n    * _Wheelchair confinement_\n* 70 undergrad students were randomly assigned to view one of the videotapes, \n    * then __rated__ the candidate's qualifications on a __1-10 scale__.\n\n\n\n* The research question: __are qualifications evaluated differently depending on the applicant's presented disability?__\n\n\n\n### Load interview data from `.txt` file\n\n\n* `.txt` files are usually tab-deliminated files\n    * `.csv` files are comma-separated files\n* `read_delim` is from the `readr` package, just like `read_csv`\n\n\n::: {.cell}\n\n```{.r .cell-code}\nemploy <- read_delim(\n  file = here::here(\"data\", \"DisabilityEmployment.txt\"), \n  delim = \"\\t\",   # tab delimited\n  trim_ws = TRUE)\n```\n:::\n\n\n`trim_ws`: \tShould leading and trailing whitespace be trimmed from each field before parsing it?\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsummary(employ)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n  disability            score      \n Length:70          Min.   :1.400  \n Class :character   1st Qu.:3.700  \n Mode  :character   Median :5.050  \n                    Mean   :4.929  \n                    3rd Qu.:6.100  \n                    Max.   :8.500  \n```\n:::\n\n```{.r .cell-code}\nemploy %>% tabyl(disability)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n disability  n percent\n    amputee 14     0.2\n   crutches 14     0.2\n    hearing 14     0.2\n       none 14     0.2\n wheelchair 14     0.2\n```\n:::\n:::\n\n\n\n\n\n\n### Factor variable: Make `disability` variable a factor variable\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nglimpse(employ)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nRows: 70\nColumns: 2\n$ disability <chr> \"none\", \"none\", \"none\", \"none\", \"none\", \"none\", \"none\", \"no…\n$ score      <dbl> 1.9, 2.5, 3.0, 3.6, 4.1, 4.2, 4.9, 5.1, 5.4, 5.9, 6.1, 6.7,…\n```\n:::\n\n```{.r .cell-code}\nemploy <- employ %>% \n  mutate(disability = factor(disability))\nglimpse(employ)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nRows: 70\nColumns: 2\n$ disability <fct> none, none, none, none, none, none, none, none, none, none,…\n$ score      <dbl> 1.9, 2.5, 3.0, 3.6, 4.1, 4.2, 4.9, 5.1, 5.4, 5.9, 6.1, 6.7,…\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nsummary(employ)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n      disability     score      \n amputee   :14   Min.   :1.400  \n crutches  :14   1st Qu.:3.700  \n hearing   :14   Median :5.050  \n none      :14   Mean   :4.929  \n wheelchair:14   3rd Qu.:6.100  \n                 Max.   :8.500  \n```\n:::\n:::\n\n\n\n\n\n### Factor variable: Change order & name of disability levels \n\n\n::: {.cell}\n\n```{.r .cell-code}\nlevels(employ$disability)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"amputee\"    \"crutches\"   \"hearing\"    \"none\"       \"wheelchair\"\n```\n:::\n\n```{.r .cell-code}\nemploy <- employ %>% \n  mutate(\n    # make \"none\" the first level\n    # by only listing the level none, all other levels will be in original order\n    disability = fct_relevel(disability, \"none\"),\n    # change the level name amputee to amputation\n    disability = fct_recode(disability, amputation = \"amputee\")\n    )\n\nlevels(employ$disability) # note the new order and new name\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"none\"       \"amputation\" \"crutches\"   \"hearing\"    \"wheelchair\"\n```\n:::\n:::\n\n\n`fct_relevel()` and `fct_recode()` are from the `forcats` package: https://forcats.tidyverse.org/index.html. `forcats` is loaded with `library(tidyverse)`.\n\n\n\n### Data viz\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(employ, aes(x=score)) +\n  geom_density() +\n  facet_wrap(~ disability)\n```\n\n::: {.cell-output-display}\n![](Day14_bsta511_code_files/figure-html/unnamed-chunk-8-1.png){width=480}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(ggridges) \nggplot(employ, \n       aes(x=score,\n           y = disability,\n           fill = disability)) + \n  geom_density_ridges(alpha = 0.4) +\n  theme(legend.position=\"none\")\n```\n\n::: {.cell-output-display}\n![](Day14_bsta511_code_files/figure-html/unnamed-chunk-9-1.png){width=480}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(employ, aes(y=score, x = disability,\n                   fill = disability)) +\n  geom_boxplot(alpha =.3) +\n  coord_flip() +\n  geom_jitter(width =.1, alpha = 0.3) +\n  theme(legend.position = \"none\")\n```\n\n::: {.cell-output-display}\n![](Day14_bsta511_code_files/figure-html/unnamed-chunk-10-1.png){width=480}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(employ, aes(x = disability, y=score, \n    fill=disability, color=disability)) +\n  geom_dotplot(binaxis = \"y\", alpha =.5) +\n  geom_hline(aes(yintercept = mean(score)), \n             lty = \"dashed\") +\n  stat_summary(fun =\"mean\", geom=\"point\", \n    size = 3, color = \"grey33\", alpha =1) +\n  theme(legend.position = \"none\")\n```\n\n::: {.cell-output-display}\n![](Day14_bsta511_code_files/figure-html/unnamed-chunk-11-1.png){width=480}\n:::\n:::\n\n\n\n\n# ANOVA\n\n\n\n## Hypotheses\n\nTo test for a difference in means across _k_ treatment groups:\n\n\\begin{align}\nH_0 &: \\mu_1 = \\mu_2 = ... = \\mu_k\\\\\n\\text{vs. } H_A&: \\text{At least one pair } \\mu_i \\neq \\mu_j\n\\end{align}\n\n\n__Hypothetical examples:__  \nIn which set (A or B) do you believe the evidence will be stronger \nthat at least one population differs from the others?\n\n__See slides__\n\n\n\n## Comparing means\n\nWhether or not two means are significantly different depends on:\n* How far apart the means are\n* How much variability there is within each treatment group\n\n__Questions:__  \n* How to measure variability between treatment groups?\n* How to measure variability within treatment groups?\n* How to compare the two measures?\n* How to determine significance?\n\n\n\n\n## ANOVA in base R\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nempl_lm <- lm(score ~ disability, data = employ)\nanova(empl_lm)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nAnalysis of Variance Table\n\nResponse: score\n           Df  Sum Sq Mean Sq F value  Pr(>F)  \ndisability  4  30.521  7.6304  2.8616 0.03013 *\nResiduals  65 173.321  2.6665                  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n:::\n:::\n\n\nHypotheses:\n\n\\begin{align}\nH_0 &: \\mu_{none} = \\mu_{amputation} = \\mu_{crutches} = \\mu_{hearing} =  \\mu_{wheelchair}\\\\\n\\text{vs. } H_A&: \\text{At least one pair } \\mu_i \\neq \\mu_j\n\\end{align}\n\nDo we reject or fail to reject $H_0$?\n\n\n\n\n\n## ANOVA tables\n\n\n__See slides__\n\n\n\n## ANOVA: Analysis of Variance \n\n__Analysis of Variance (ANOVA)__ compares the variability between treatments to the variability within treatments \n\n$$\\sum_{i = 1}^k \\sum_{j = 1}^{n_i}(y_{ij} -\\bar{y}_{..})^2 \\ \\ = \\ \\sum_{i = 1}^k n_i(\\bar{y}_{i.}-\\bar{y}_{..})^2 \\ \\ + \\ \\ \\sum_{i = 1}^k\\sum_{j = 1}^{n_i}(y_{ij}-\\bar{y}_{i.})^2$$\n\n\n\n\n## Notation\n\n\n* _k_ treatment groups\n* _n_ observations in each of the _k_ treatment groups\n* Total sample size is $N=\\sum_{i=1}^{k}n_i$\n* $\\bar{y}_{i.}$ = mean of observations in treatment _i_\n* $\\bar{y}_{..}$ = mean of _all_ observations\n\n\n\n| Observation | *i* = 1      | *i* = 2      | *i* = 3      | $\\ldots$ |*i* = *k*| overall|\n| :----------| :---------:| :---------:|:----------:|:----:|:-----:|:-----:|\n| *j* = 1       | $y_{11}$ | $y_{21}$ | $y_{31}$ | $\\ldots$ | $y_{k1}$ ||\n| *j* = 2       | $y_{12}$ | $y_{22}$ | $y_{32}$ | $\\ldots$ | $y_{k2}$ ||\n| *j* = 3       | $y_{13}$ | $y_{23}$ | $y_{33}$ | $\\ldots$ | $y_{k3}$ ||\n| *j* = 4       | $y_{14}$ | $y_{24}$ | $y_{34}$ | $\\ldots$ | $y_{k4}$ ||\n| $\\vdots$    | $\\vdots$ | $\\vdots$ | $\\vdots$ | $\\ddots$ | $\\vdots$ ||\n| *j* = $n_i$     | $y_{1n}$ | $y_{2n}$ | $y_{3n}$ | $\\ldots$ | $y_{kn}$ ||\n| Means       | $\\bar{y}_{1.}$ | $\\bar{y}_{2.}$ | $\\bar{y}_{3.}$ | $\\ldots$ | $\\bar{y}_{k.}$ | $\\bar{y}_{..}$ |\n| Variance    | ${s}^2_{1.}$ | ${s}^2_{2.}$ | ${s}^2_{3.}$ | $\\ldots$ | ${s}^2_{k.}$ | ${s}^2_{..}$ |\n\n\n\n\n\n\n## Total Sums of Squares Visually\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](Day14_bsta511_code_files/figure-html/unnamed-chunk-13-1.png){width=480}\n:::\n:::\n\n\n\nTotal Sums of Squares:\n\n$$\\sum_{i = 1}^k \\sum_{j = 1}^{n_i}(y_{ij} -\\bar{y}_{..})^2 = (N-1)s^2_{..}$$\nwhere $N=\\sum_{i=1}^{k}n_i$ is the total sample size and $s^2_{..}$ is the grand standard deviation of all the observations\n\n* This is the sum of the squared differences between each observed $y_{ij}$ value and the *grand mean*, $\\bar{y}_{..}$. \n\n* That is, it is the total deviation of the $y_{ij}$'s from the grand mean. \n\n\n\n\n\n\n### Calculate Total Sums of Squares \n\n\nTotal Sums of Squares:\n\n$$\\sum_{i = 1}^k \\sum_{j = 1}^{n_i}(y_{ij} -\\bar{y}_{..})^2 = (N-1)s^2_{..}$$\nwhere $N=\\sum_{i=1}^{k}n_i$ is the total sample size and $s^2_{..}$ is the grand standard deviation of all the observations\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n(Ns <- employ %>% group_by(disability) %>% count())\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 5 × 2\n# Groups:   disability [5]\n  disability     n\n  <fct>      <int>\n1 none          14\n2 amputation    14\n3 crutches      14\n4 hearing       14\n5 wheelchair    14\n```\n:::\n\n```{.r .cell-code}\n(SST <- (sum(Ns$n) - 1) * sd(employ$score)^2)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 203.8429\n```\n:::\n:::\n\n\n\n\n\n\n## ANOVA: Analysis of Variance \n\n__ANOVA__ compares the variability between treatments to the variability within treatments \n\n\n\n\n## Sums of Squares due to Treatments Visually (\"between\" treatments)\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](Day14_bsta511_code_files/figure-html/unnamed-chunk-15-1.png){width=480}\n:::\n:::\n\n\n\nSums of Squares due to Treatments:\n\n$$SSTr = \\sum_{i = 1}^k n_i(\\bar{y}_{i.}-\\bar{y}_{..})^2$$\n\n* This is the sum of the squared differences between each *treatment* mean, $\\bar{y}_{i.}$, and the *grand mean*, $\\bar{y}_{..}$. \n\n* That is, it is the deviation of the treatment means from the grand mean.\n\n* Also called the Model SS, or $SS_{model}.$\n\n\n\n\n\n\n### Calculate Sums of Squares due to Treatments (\"between\" treatments)\n\n\nSums of Squares due to Treatments:\n\n$$SSTr = \\sum_{i = 1}^k n_i(\\bar{y}_{i.}-\\bar{y}_{..})^2$$\n\n\n::: {.cell}\n\n```{.r .cell-code}\nxbar_groups <- employ %>% \n  group_by(disability) %>% \n  summarise(mean = mean(score))\nxbar_groups\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 5 × 2\n  disability  mean\n  <fct>      <dbl>\n1 none        4.9 \n2 amputation  4.43\n3 crutches    5.92\n4 hearing     4.05\n5 wheelchair  5.34\n```\n:::\n\n```{.r .cell-code}\n(SSTr <- 14*sum(\n  (xbar_groups$mean - mean(employ$score))^2))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 30.52143\n```\n:::\n:::\n\n\n\n\n## Sums of Squares Error Visually (within treatments)\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](Day14_bsta511_code_files/figure-html/unnamed-chunk-17-1.png){width=480}\n:::\n:::\n\n\n\nSums of Squares Error:\n\n$$SSE = \\sum_{i = 1}^k\\sum_{j = 1}^{n_i}(y_{ij}-\\bar{y}_{i.})^2 = \\sum_{i = 1}^k(n_i-1)s_{i.}^2$$\nwhere $s_{i.}$ is the standard deviation of the $i^{th}$ treatment\n\n* This is the sum of the squared differences between each observed $y_{ij}$ value and its treatment mean $\\bar{y}_{i.}$. \n\n* That is, it is the deviation of the $y_{ij}$'s from the predicted score by treatment.\n\n* Also called the residual sums of squares, or $SS_{residual}.$\n\n\n\n\n\n\n\n### Calculate Sums of Squares Error (within treatments)\n\n\nSums of Squares Error:\n\n$$SSE = \\sum_{i = 1}^k\\sum_{j = 1}^{n_i}(y_{ij}-\\bar{y}_{i.})^2 = \\sum_{i = 1}^k(n_i-1)s_{i.}^2$$\nwhere $s_{i.}$ is the standard deviation of the $i^{th}$ treatment\n\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsd_groups <- employ %>% \n  group_by(disability) %>% \n  summarise(SD = sd(score))\nsd_groups\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 5 × 2\n  disability    SD\n  <fct>      <dbl>\n1 none        1.79\n2 amputation  1.59\n3 crutches    1.48\n4 hearing     1.53\n5 wheelchair  1.75\n```\n:::\n\n```{.r .cell-code}\n(SSE <- sum(\n  (14-1)*sd_groups$SD^2))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 173.3214\n```\n:::\n:::\n\n\n\n\n\n\n## Verify _SST = SSTr + SSE_\n\n__ANOVA__ compares the variability between treatments to the variability within treatments \n\n\n$$\\sum_{i = 1}^k \\sum_{j = 1}^{n_i}(y_{ij} -\\bar{y}_{..})^2 \\ \\ = \\ \\ n_i\\sum_{i = 1}^k(\\bar{y}_{i.}-\\bar{y}_{..})^2 \\ \\ + \\ \\ \\sum_{i = 1}^k\\sum_{j = 1}^{n_i}(y_{ij}-\\bar{y}_{i.})^2$$\n\n$$(N-1)s^2_{..} \\ \\ = \\ \\sum_{i = 1}^k n_i(\\bar{y}_{i.}-\\bar{y}_{..})^2 \\ \\ + \\ \\ \\sum_{i = 1}^k(n_i-1)s_{i.}^2$$\n\n\n::: {.cell}\n\n```{.r .cell-code}\nSST\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 203.8429\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nSSTr + SSE\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 203.8429\n```\n:::\n:::\n\n\n\n\n\n## Thinking about the F-statistic\n\n\n__[If the treatments are actually different, then which of these is more accurate?]{style=\"color:green\"}__\n\n1. The variability between treatments should be higher than the variability within treatments\n1. The variability within treatments should be higher than the variability between treatments\n\n\n__[If there really is a difference between the treatments, we would expect the F-statistic to be which of these: ]{style=\"color:green\"}__\n\n1. Higher than we would observe by random chance\n1. Lower than we would observe by random chance\n\n$$F = \\frac{MSG}{MSE}$$\n\n\n\n\n## ANOVA in base R\n\n\n::: {.cell}\n\n```{.r .cell-code}\nempl_lm <- lm(score ~ disability, data = employ)\ntidy(anova(empl_lm))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 2 × 6\n  term          df sumsq meansq statistic p.value\n  <chr>      <int> <dbl>  <dbl>     <dbl>   <dbl>\n1 disability     4  30.5   7.63      2.86  0.0301\n2 Residuals     65 173.    2.67     NA    NA     \n```\n:::\n:::\n\n\nHypotheses:\n\n\\begin{align}\nH_0 &: \\mu_{none} = \\mu_{amputation} = \\mu_{crutches} = \\mu_{hearing} =  \\mu_{wheelchair}\\\\\n\\text{vs. } H_A&: \\text{At least one pair } \\mu_i \\neq \\mu_j\n\\end{align}\n\nDo we reject or fail to reject $H_0$?\n\n\n\n## Conclusion to hypothesis test\n\n\\begin{align}\nH_0 &: \\mu_{none} = \\mu_{amputation} = \\mu_{crutches} = \\mu_{hearing} =  \\mu_{wheelchair}\\\\\n\\text{vs. } H_A&: \\text{At least one pair } \\mu_i \\neq \\mu_j\n\\end{align}\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntidy(anova(empl_lm))  # cleaner anova output\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 2 × 6\n  term          df sumsq meansq statistic p.value\n  <chr>      <int> <dbl>  <dbl>     <dbl>   <dbl>\n1 disability     4  30.5   7.63      2.86  0.0301\n2 Residuals     65 173.    2.67     NA    NA     \n```\n:::\n\n```{.r .cell-code}\nround(broom::tidy(anova(empl_lm))$p.value[1],2)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.03\n```\n:::\n:::\n\n\n\n* Use $\\alpha$ = 0.05.\n* Do we reject or fail to reject $H_0$?\n\n__Conclusion statement__:\n* There is sufficient evidence that at least one of the disability groups has a mean employment score statistically different from the other groups. ( $p$-value = 0.03).\n\n\n\n\n## Assumptions for ANOVA \n\n[__IF__ the following conditions hold:]{style=\"color:green\"}\n\n1. the null hypothesis is true\n1. sample sizes in each treatment group are large (each $n \\ge 30$) \n    * OR the data are relatively normally distributed\n1. variability is \"similar\" in all treatment groups:\n    * Is the within treatment group variability about the same for each treatment group?\n    * As a rough rule of thumb, this assumption is _violated if the standard deviation of one treatment group is more than double the standard deviation of another treatment group_\n\n[__THEN__ the sampling distribution of the   \n__F-statistic__ is an __F-distribution__]{style=\"color:green\"}\n\n\nChecking the __equal variance__ assumption:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsd_groups # previously defined\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 5 × 2\n  disability    SD\n  <fct>      <dbl>\n1 none        1.79\n2 amputation  1.59\n3 crutches    1.48\n4 hearing     1.53\n5 wheelchair  1.75\n```\n:::\n\n```{.r .cell-code}\nmax(sd_groups$SD) / min(sd_groups$SD)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 1.210425\n```\n:::\n:::\n\n\n\n\n## Testing variances (Assumption 3)\n\n__Bartlett’s test for equal variances__\n\n* $H_0:$ variances of treatment levels are equal\n* $H_A:$ variances of treatment levels are NOT equal\n\n_Note: $H_A$ is same as saying that at least one of the treatment levels has a different variance__\n\n* Caution: Bartlett's test assumes the data in each treatment group are normally distributed. Do not use if data do not satisfy the normality assumption. \n\n\n::: {.cell}\n\n```{.r .cell-code}\nbartlett.test(score ~ disability, data = employ)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n\tBartlett test of homogeneity of variances\n\ndata:  score by disability\nBartlett's K-squared = 0.7016, df = 4, p-value = 0.9511\n```\n:::\n:::\n\n\n* Levene's test for equality of variances is not as restrictive: see https://www.statology.org/levenes-test-r/ \n\n\n## The F-distribution\n\nThe F-distribution is skewed right:\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](Day14_bsta511_code_files/figure-html/unnamed-chunk-25-1.png){width=480}\n:::\n:::\n\n\n\n\nThe __F-distribution__ has two degrees of freedom:\n\n* one for the numerator of the ratio (k – 1) and \n* one for the denominator (N – k)\n\n$p$-__value__:  \nFor F-statistics, the _p_-value (the area as extreme or more extreme) is always the __upper tail__.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# p-value using F-distribution\npf(2.8646, df1=5-1, df2=70-5, \n   lower.tail = FALSE)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.02999488\n```\n:::\n:::\n\n\n\n\n## Which treatment groups are statistically different?\n\n\n* So far we've only determined that at least one of the treatment groups is different from the others, but we don't know which.\n\n* What's your guess?\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](Day14_bsta511_code_files/figure-html/unnamed-chunk-27-1.png){width=480}\n:::\n:::\n\n\n\n\n\n# Post-hoc testing for ANOVA\n## _determining which groups are statistically different_\n\n\n## Post-hoc testing: pairwise t-tests\n\n\n* In post-hoc testing we run all the pairwise t-tests comparing the means from each pair of groups.\n* With 5 groups, this involves doing ${5 \\choose 2} = \\frac{5!}{2!3!} = \\frac{5\\cdot 4}{2}= 10$ different pairwise tests.\n\n__Problem:__\n\nAlthough test has an $\\alpha$ chance of a Type I error (finding a difference between a pair that aren't different), the overall Type I error rate will be much higher when running many tests simultaneously.\n\n\n\n\n\\begin{align}\nP(\\text{making an error}) = & \\alpha\\\\\nP(\\text{not making an error}) = & 1-\\alpha\\\\\nP(\\text{not making an error in m tests}) = & (1-\\alpha)^m\\\\\nP(\\text{making at least 1 error in m tests}) = & 1-(1-\\alpha)^m\n\\end{align}\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](Day14_bsta511_code_files/figure-html/unnamed-chunk-28-1.png){width=576}\n:::\n:::\n\n\n\n\n\n\n## The Bonferroni Correction (1/2)\n\n\n\nA very conservative (but very popular) approach is to divide the $\\alpha$ level by how many tests $m$ are being done:\n\n$$\\alpha_{Bonf} = \\frac{\\alpha}{m}$$\n\n* This is equivalent to multiplying the  \n_p_-values by m:\n\n$$p\\textrm{-value} < \\alpha_{Bonf} = \\frac{\\alpha}{m}$$ \nis the same as\n$$m \\cdot (p\\textrm{-value}) < \\alpha$$\nThe Bonferroni correction is popular since it's very easy to implement.\n\n\n\n* The __plot below__ shows the __[likelihood of making at least one Type I error]{style=\"color:green\"}__ depending on how may tests are done.\n* Notice the likelihood decreases very quickly\n    * Unfortunately the likelihood of a Type II error is increasing as well\n    * It becomes \"harder\" and harder to reject $H_0$ if doing many tests.\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](Day14_bsta511_code_files/figure-html/unnamed-chunk-29-1.png){width=576}\n:::\n:::\n\n::: {.cell}\n\n:::\n\n\n\n\n\n\n## The Bonferroni Correction (2/2)\n\n\nPairwise t-tests without any _p_-value adjustments:\n\n::: {.cell}\n\n```{.r .cell-code}\npairwise.t.test(employ$score, \n                employ$disability, \n                p.adj=\"none\") \n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n\tPairwise comparisons using t tests with pooled SD \n\ndata:  employ$score and employ$disability \n\n           none   amputation crutches hearing\namputation 0.4477 -          -        -      \ncrutches   0.1028 0.0184     -        -      \nhearing    0.1732 0.5418     0.0035   -      \nwheelchair 0.4756 0.1433     0.3520   0.0401 \n\nP value adjustment method: none \n```\n:::\n:::\n\n\n\n\n\nPairwise t-tests __[with Bonferroni _p_-value adjustments]{style=\"color:green\"}__:\n\n::: {.cell}\n\n```{.r .cell-code}\npairwise.t.test(employ$score,  \n                employ$disability, \n                p.adj=\"bonferroni\")  \n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n\tPairwise comparisons using t tests with pooled SD \n\ndata:  employ$score and employ$disability \n\n           none  amputation crutches hearing\namputation 1.000 -          -        -      \ncrutches   1.000 0.184      -        -      \nhearing    1.000 1.000      0.035    -      \nwheelchair 1.000 1.000      1.000    0.401  \n\nP value adjustment method: bonferroni \n```\n:::\n:::\n\n\nSince there were 10 tests, all the _p_-values were multiplied by 10.\n\n\n\n\n\n\n## Tukey's Honest Significance Test (HSD) (1/3)\n\n\n* Tukey's Honest Significance Test (HSD) controls the \"family-wise probability\" of making a Type I error using a much less conservative method than Bonferroni\n* __It is specific to ANOVA__\n* In addition to adjusted _p_-values, it also calculates Tukey adjusted CI's \n\nThe function `TukeyHSD()` creates a set of __confidence intervals__ on the differences between means with the specified __family-wise probability of coverage__.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# need to run the model as an `aov` instead of `lm`\nempl_aov <- aov(score ~ disability, data = employ) \nanova(empl_aov)  \n```\n\n::: {.cell-output .cell-output-stdout}\n```\nAnalysis of Variance Table\n\nResponse: score\n           Df  Sum Sq Mean Sq F value  Pr(>F)  \ndisability  4  30.521  7.6304  2.8616 0.03013 *\nResiduals  65 173.321  2.6665                  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n:::\n:::\n\n\n\n\n\n\n\n## Tukey's Honest Significance Test (HSD) (2/3)\n\nBoth Tukey HSD p-values and CI's for all pairwise differences.\n\n::: {.cell}\n\n```{.r .cell-code}\nTukeyHSD(x=empl_aov, conf.level = 0.95) \n```\n\n::: {.cell-output .cell-output-stdout}\n```\n  Tukey multiple comparisons of means\n    95% family-wise confidence level\n\nFit: aov(formula = score ~ disability, data = employ)\n\n$disability\n                            diff        lwr        upr     p adj\namputation-none       -0.4714286 -2.2031613  1.2603042 0.9399911\ncrutches-none          1.0214286 -0.7103042  2.7531613 0.4686233\nhearing-none          -0.8500000 -2.5817328  0.8817328 0.6442517\nwheelchair-none        0.4428571 -1.2888756  2.1745899 0.9517374\ncrutches-amputation    1.4928571 -0.2388756  3.2245899 0.1232819\nhearing-amputation    -0.3785714 -2.1103042  1.3531613 0.9724743\nwheelchair-amputation  0.9142857 -0.8174470  2.6460185 0.5781165\nhearing-crutches      -1.8714286 -3.6031613 -0.1396958 0.0277842\nwheelchair-crutches   -0.5785714 -2.3103042  1.1531613 0.8812293\nwheelchair-hearing     1.2928571 -0.4388756  3.0245899 0.2348141\n```\n:::\n:::\n\n\n\n\n\n## Tukey's Honest Significance Test (HSD) (3/3)\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nplot(TukeyHSD(x=empl_aov, conf.level = 0.95))\n```\n\n::: {.cell-output-display}\n![](Day14_bsta511_code_files/figure-html/unnamed-chunk-35-1.png){width=576}\n:::\n:::\n\n\n\n\n* Visualization of pairwise CI's\n\n* __[Which pair(s) of disabilities are significant after Tukey's adjustments?]{style=\"color:green\"}__\n\n\n\n\n\n# There are many more multiple testing adjustment procedures\n\n\n* Bonferroni is popular because it's so easy to apply\n* Tukey's HSD is usually used for ANOVA\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# default is Holm's adjustments\npairwise.t.test(employ$score, \n                employ$disability) \n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n\tPairwise comparisons using t tests with pooled SD \n\ndata:  employ$score and employ$disability \n\n           none  amputation crutches hearing\namputation 1.000 -          -        -      \ncrutches   0.719 0.165      -        -      \nhearing    0.866 1.000      0.035    -      \nwheelchair 1.000 0.860      1.000    0.321  \n\nP value adjustment method: holm \n```\n:::\n:::\n\n\n\n\nPairwise t-tests with __false discovery rate (fdr)__ _p_-value adjustments (popular in omics):\n\n::: {.cell}\n\n```{.r .cell-code}\npairwise.t.test(employ$score, \n                employ$disability, \n                p.adj=\"fdr\") \n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n\tPairwise comparisons using t tests with pooled SD \n\ndata:  employ$score and employ$disability \n\n           none  amputation crutches hearing\namputation 0.528 -          -        -      \ncrutches   0.257 0.092      -        -      \nhearing    0.289 0.542      0.035    -      \nwheelchair 0.528 0.287      0.503    0.134  \n\nP value adjustment method: fdr \n```\n:::\n:::\n\n\n\n\n\n\n\n\n\n## Multiple testing\n\n _post-hoc testing vs. testing many outcomes_\n\n\n\n## Multiple testing: controlling the Type I error rate\n\n\n* The multiple testing issue is not unique to ANOVA post-hoc testing.\n* It is also a concern when running separate tests for many related outcomes.\n* __[Beware of _p_-hacking!]{style=\"color:darkorange\"}__\n\n__Problem:__\n\nAlthough test has an $\\alpha$ chance of a Type I error (finding a difference between a pair that aren't different), the overall Type I error rate will be much higher when running many tests simultaneously.\n\n\n\n\n\\begin{align}\nP(\\text{making an error}) = & \\alpha\\\\\nP(\\text{not making an error}) = & 1-\\alpha\\\\\nP(\\text{not making an error in m tests}) = & (1-\\alpha)^m\\\\\nP(\\text{making at least 1 error in m tests}) = & 1-(1-\\alpha)^m\n\\end{align}\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](Day14_bsta511_code_files/figure-html/unnamed-chunk-38-1.png){width=576}\n:::\n:::\n",
    "supporting": [
      "Day14_bsta511_code_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}